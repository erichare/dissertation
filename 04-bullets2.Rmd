\chapter{A MODERN BULLET MATCHING APPLICATION}

\begin{center}

A paper to be submitted to the \textbf{Journal of Forensic Science}. \\
Eric Hare, Heike Hofmann, Alicia Carriquiry

\textbf{Abstract}

\end{center}

Bullet matching is a process used to determine whether two bullets have been fired from the same gun barrel. While traditionally a manual process performed by trained forensic examiners, recent work has been done to add statistical validity and objectivity to the procedure. In this paper, we build upon the algorithms explored in Automatic Matching of Bullet Lands by describing a database structure which tracks every parameter used, and allows for the seamless replication of results by researchers, adding a layer of reproducibility to the bullet matching process. Finally, we describe a front-end web application which utilizes the algorithms and the database to allow bullet matching to be done more efficiently.

\newpage

# Background

The need for advancements in terms of scientific objectivity and reproducibility of forensic methods is well known. Note, for example, the recent report by the President's Council of Advisors on Science on Technology (PCAST) [@pcast2016]. The report references a number of areas of common practice in the field in which subjectivity is far too common, including but not limited to fingerprint analysis, bitemark analysis and firearms analysis.

Work has been done to address these concerns and add objectivity to these procedures. In the case of firearms analysis, the focus of this paper, some examples include @vorburger:2011, @thompson:2013, and @riva:2014. Our own work, "Automatic Matching of Bullet Lands", describes procedures used to produce an estimate of the probability of a match between two bullet lands. It does so by deriving a number of features, some from the literature and some original, and computing these features on pairs of reference bullets from the NIST Ballistics Toolmark Research Database (NBTRD). The algorithms used are published as open-source R code available in the package `bulletr` [@bulletr]. In spite of these steps towards transparency, however, the process of duplicated and assessing the performance of the algorithm in hopes of improving predictive accuracy was cumbersome in a number of ways:

1. Doing so requires specialized statistical software (specifically, R and associated R packages)
2. Computing statistics on all pairs of bullet lands is a time consuming process even on high-powered machines (on the order of several days)
3. Updates to our `bulletr` package, or any package dependencies of `bulletr`, may change the results such that our findings are not completely reproducible even if each step is correctly followed

In this paper, we add a new layer of reproducibility to the algorithms to allow for forensic scientists, statisticians, and other interested researchers to duplicate and iterate on the results in a seamless fashion. We do so by introducing a new database structure that supplements the NIST database by storing all necessary parameters and intermediate results needed to arrive at a matching probability between two bullet lands. We describe the structure from a technical perspective, and then describe the front-end and back-end application structure which utilizes the database to provide results to the researchers. Finally, we provide a case study analysis on features of bullet land pairs as an example of the capabiilities of this structure when it is leveraged.

# Database Structure

Figure \ref{fig:database_schema} displays the database schema along with links between the relevant id columns. This structure provides the necessary links between the raw input data, and the processed signatures used to compute features and ultimately provide matching probabilities between pairs of lands. This diagram will be explained in depth in this section.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{images/schema.png}
\caption{A schematic of the database.}
\label{fig:database_schema}
\end{figure}

We can connect to the database using the `dplyr` package.

```{r, message=FALSE, cache=FALSE}
library(xtable)
library(RMySQL)
library(tidyverse)
library(bulletr)
library(gridExtra)
library(randomForest)
library(caret)
library(broom)

dbname <- "bullets"
user <- "buser"
password <- readLines("buser_pass.txt")
host <- "50.81.214.252"
port <- 3306

my_db <- src_mysql(dbname, host, port, user, password)
```

The remainder of this section will walk through the most relevant database tables, and include reproducible R code for accessing, parsing, and displaying the data.

## Data

The data table is essentially a mirror of the bullets stored in the NBTRD. It currently includes a long-form version of the two Hamby bullet sets (Set 252 and Set 44) [@hamby:2009] and the Cary Persistence study [@cary]. A sample of 20 rows of this table can be seen in Table \ref{tab:data}. The land id column identifies the bullet land under consideration. The x coordinate is the location along the shorter axis, while the y coordinate is along the longer axis. The value column represents the height of the bullet at that particular location.

```{r}
my_data <- tbl(my_db, "data")

# Get Hamby Barrel 1 Bullet 1 Land 3
result <- my_data %>% 
    filter(land_id == 39, !is.na(value)) %>%
    arrange(x, y) %>%
    head(n = 20) %>%
    as.data.frame
```

```{r, echo=FALSE, message=FALSE, results='asis'}
print(xtable(result, digits = c(0, 0, 0, 0, 2, 2), label = "tab:data", caption = "A sample of 20 rows of the data table. The land id column identifies the bullet land under consideration. The x coordinate is the location along the shorter axis, while the y coordinate is along the longer axis. The value column represents the height of the bullet at that particular location."), comment = FALSE)
```

In comparison to a regular x3p file, this data table is less space efficient. An x3p file uses a surface matrix of dimension $(x, y)$ where the value of each $(x_i, y_j)$ is the height of the bullet at $x = i$ and $y = j$. Our expanded version of the format turns each cell into a single row $x_i, y_j, z_{ij}$. Where $z_{ij}$ where $z_{ij}$ is the height of the bullet at $x = i$, $y = j$. Thus, for a bullet with 500 $x$ values and 1572 $y$ values (as in land id 39), an x3p file uses a matrix of size 786000, while we use a data frame of 786000 rows and 3 columns, storing $3x$ as much information. While certainly less space efficient, the format allows for easy querying of specific lands or specific profiles from the database.

## Metadata

As shown in Table \ref{tab:metadata}, the metadata table includes one row for each unique bullet land. The name of the bullet is derived from the file path, as provided by the NBTRD. Several other parameters are given, including the number of profiles, (x values), number of observations per profile (y values), and the increments of each in micrometers. (in this case, one x unit is equivalent to 1.5625 micrometers). Note that this table includes parameters that are derived solely from the properties of the data itself. Hence, the previous data table in conjunction with metadata forms the information needed to generate x3p files. Conversely, x3p files can be used to regenerate the data contained in both these tables.

```{r}
my_metadata <- tbl(my_db, "metadata")

result <- my_metadata %>% 
    filter(land_id >= 61, land_id <= 72) %>%
    as.data.frame
```

```{r, echo=FALSE, results='asis'}
print(xtable(result[,1:7], digits = c(0, 0, 0, 0, 0, 0, 0, 0), label = "tab:metadata", caption = "A sample of 12 rows of the metadata table. The land id column identifies the bullet land under consideration. The name of the bullet is derived from the file path, as provided by the NBTRD. Several other parameters are given, including the number of profiles, (x values), number of observations per profile (y values), and the increments of each in micrometers. (in this case, one x unit is equivalent to 1.5625 micrometers)"), comment = FALSE, include.rownames = FALSE)
```

## Metadata Derived

Similarly to the metadata table, the metadata_derived table (Sampled in Table \ref{tab:metadata_derived}) includes one row per bullet land. The difference is that the columns of this table were derived by our algorithm rather than properties of the data. The run_id, which will be discussed in more depth later, indicates the algorithm run that yielded the following derived parameters.

```{r}
my_metadata_derived <- tbl(my_db, "metadata_derived")

result <- my_metadata_derived %>% 
    filter(land_id >= 61, land_id <= 72) %>%
    as.data.frame
```

```{r, echo=FALSE, results='asis'}
print(xtable(result, digits = c(0, 0, 0, 0, 4, 4, 0, 0), label = "tab:metadata_derived", caption = "A sample of 12 rows of the metadata\\_derived table. Once again, a land id identifies a particular bullet land. The run id, which will be discussed in more depth later, indicates the algorithm run that yielded the following derived parameters."), comment = FALSE, include.rownames = FALSE)
```

A number of derived parameters are given for a particular land and a particular run:

1. **ideal_crosscut** - The location of the ideal cross section (or ideal x coordinate) at which to extract a profile, as given by Hare, Hofmann, Carriquiry (2017).
2. **left_twist** - The calculated twist of the scan as determined by the left shoulder.
3. **right_twist** - The calculated twist of the scan as determined by the right shoulder.
4. **left_sample** - The number of samples used to compute the left twist.
5. **right_sample** - The number of samples used to compute the right twist.

## Profiles

Table \ref{tab:profiles} displays 10 profiles from land id 39, using the first 20 x coordinate values. Profiles are defined by properties of the grooves or shoulders. Hence, given this information, we can post-process the data table to extract particular profiles. For instance, we can use profile_id 32448, which is the profile obtained by extracting at x = 100 for land_id 39. Using properties of the grooves as determined by our algorithm, we can extract the the profile with the shoulders and grooves removed.

```{r}
my_profiles <- tbl(my_db, "profiles")

result <- my_profiles %>% 
    filter(land_id == 39, x > 92, x < 107) %>%
    select(-groove_left_pred, -groove_right_pred) %>%
    as.data.frame
```

```{r, echo=FALSE, results='asis'}
print(xtable(result, digits = c(0, 0, 0, 0, 2, 2, 2), label = "tab:profiles", caption = "A sample of 10 rows of the profiles table. A profile id is uniquely identified by a land id, a run id, and an x value."), comment = FALSE, include.rownames = FALSE)
```

Figure \ref{fig:prof} displays the profile obtained by extracting land id 39 at x = 100. Dashed vertical lines indicate the location of the shoulders. Within the bounds of the dashed line, the profiles that are relevant for bullet matching are obtained.

```{r prof, message=FALSE, warning=FALSE, fig.height=3, fig.width=6, fig.cap='The profile obtained by extracting land id 39 at x = 100. Dashed vertical lines indicate the location of the shoulders. Within the bounds of the dashed line, the profiles that are relevant for bullet matching are obtained.'}
myprof <- filter(result, x == 100)

land39 <- my_data %>% 
    filter(land_id == 39, x == 100) %>%
    as.data.frame

ggplot(data = land39, aes(x = y, y = value)) +
    geom_line() +
    geom_vline(xintercept = myprof$groove_left, linetype = 2) +
    geom_vline(xintercept = myprof$groove_right, linetype = 2) +
    theme_bw()
```

## Signatures

The land signature represents the processed data that is ultimately used for matching. In our case, a land signature represents the smoothed and processed residuals obtained from fitting a Locally Weighted Scatterplot Smoothing Regression (LOESS) to the profiles from above. Figure \ref{fig:sigs} displays the signature obtained by processing the profile of land id 39 at x = 100. It can be seen that the signature represents an attempt at reducing a bullet land to the peaks and valleys that represent striations, by removing the global structure of the bullet that dominates the view of the profile.

```{r sigs, message=FALSE, warning=FALSE, fig.height=3, fig.width=6, fig.cap='The signature obtained by processing the profile of land id 39 at x = 100.'}
my_signatures <- tbl(my_db, "signatures")

result <- my_signatures %>% 
    filter(profile_id == myprof$profile_id, run_id == 1) %>%
    as.data.frame

ggplot(data = result, aes(x = y, y = l30)) +
    geom_line() +
    theme_bw()
```

## CCF

The CCF table contains features computed on cross-comparisons between different signatures. The name is a bit of a misnomer; the ccf, or cross-correlation function, is only one of the features.  Table \ref{tab:ccf} displays a subset of the derived features for a comparison of the derived profile for land id 39, from above, with six other land profiles. This land's known match is the fourth row in the table, and the features immediately stand out as more pronounced, including a ccf above 90% and a number of matches far exceeding the other comparisons.

```{r}
my_ccf <- tbl(my_db, "ccf")

result <- my_ccf %>% 
    filter(profile1_id == myprof$profile_id, 
           compare_id == 4) %>%
    select(profile1_id, profile2_id, ccf, rough_cor, D, overlap, matches, cms, sum_peaks) %>%
    collect() %>%
    slice(5:10) %>%
    as.data.frame
```

```{r, echo=FALSE, results='asis'}
print(xtable(result, digits = c(0, 0, 0, 3, 3, 3, 3, 3, 3, 3), label = "tab:ccf", caption = "A subset of the derived features for a comparison of the derived profile for land id 39, from above, with six other land profiles. This land's known match is the fourth row in the table, and the features immediately stand out as more pronounced, including a ccf above .9 and a number of matches far exceeding the other comparisons."), comment = FALSE, include.rownames = FALSE)
```

# Case Study: Feature Analysis

With the database structure defined, we turn our attention to using the database to perform a feature analysis using the bullets provided in the NBTRD. The modular structure of the database allows us to extract pre-derived features without performing the intermediate computations, which in turn allows for easier in depth exploration.

## Feature Standardization

To start, we introduce each feature provided in the CCF database table. Table \ref{tab:ccf1} provides the first eight columns of the CCF table, and Table \ref{tab:ccf2} provides the remaining seven columns.

```{r, echo=FALSE, results='asis'}
result <- my_ccf %>%
    filter(compare_id == 4) %>%
    head %>%
    collect %>%
    select(1:8) %>%
    as.data.frame

print(xtable(result, digits = c(0, 0, 0, 0, 4, 4, 4, 4, 4), label = "tab:ccf1", caption = "A sample of six land-to-land comparisons, and derived features for these comparisons."), comment = FALSE, include.rownames = FALSE)
```

```{r, echo=FALSE, results='asis'}
result2 <- my_ccf %>%
    filter(compare_id == 4) %>%
    head %>%
    collect %>%
    select(9:ncol(.)) %>%
    as.data.frame

print(xtable(result2, digits = c(4, 4, 4, 4, 4, 4, 4, 4), label = "tab:ccf2", caption = "The remaining derived features for the previous six land-to-land comparisons."), comment = FALSE, include.rownames = FALSE)
```

The `compare_id`, `profile1_id`, and `profile2_id` uniquely identify a particular cross-comparison between two profiles, with the given `compare_id` parameters. The remaining columns are the relevant features for the comparison. The definitions of the features have been generalized to account for the possibility of handling degraded bullet conditions, where only fragments of lands can be recovered. The definitions of each feature are given below, where $f(t)$ represents the height values of the first profile, and $g(t)$ the height values of the second:

- **ccf** (%) is the maximum value of the Cross-Correlation function evaluated at the optimal alignment. The Cross-Correlation function is defined as $C(\tau) = \int_{-\infty}^{\infty} f(t)g(t + \tau)dt$ where $\tau$ represents the the lag of the second signature [@vorburger:2011]. 
- **rough_cor** (%) is a new feature representing the correlation between the two signatures after performing a second LOESS smoothing stage and subtracting the result from the original signatures. This attempts to model the roughness of the surface after removing the waviness.
- **lag** (mm) Is the optimal lag for the ccf value.
- **D** (mm) is the Euclidean vertical distance between each height value of the aligned signatures. This is defined as $D^2 = \frac{1}{\text{\#}t}\sum_t \left[f(t) - g(t)\right]^2$. This is a measure of the total variation between two functions [@clarkson1933definitions].
- **sd_D** (mm) provides the standard deviation of the values of *D* from above.
- **signature_length** (mm) is the overall length of the smallest of the two aligned signatures.
- **overlap** (%) provides the percentage of the two signatures that overlap after the alignment stage.
- **matches** (per mm) is the number of matching peaks/valleys (striae) per millimeter of the overlapping portion of the aligned signatures.
- **mismatches** (per mm) is the number of mismatching peaks/valleys (striae) per millimeter of the overlapping portion of the aligned signatures.
- **cms** (per mm) is the number of consecutively matching peaks/valleys (striae) per millimeter of the overlapping portion of the aligned signatures [@biasotti:1959, @thompson:2013].
- **non_cms** (per mm) is the number of consecutive mismatching peaks/valleys (striae) per millimeter of the overlapping portion of the aligned signatures.
- **sum_peaks** (per mm) is the the sum of the average heights of matched striae.

The `rough_cor` or Roughness Correlation is derived by performing a second smoothing step, and subtracting the result from the original signatures. This creates a new signature which eliminates some of the overall structure, allowing global deformations to have less of an influence on the model output. Where the roughness correlation is most useful is in a scenario like Figure \ref{fig:roughcorgood}. This figure shows the alignment of profile 40977 with 47600. The top panel shows the smoothed signatures. The middle panel overlays a LOESS fit to the average of the two signatures. Finally, to derive the roughness correlation, this LOESS is subtracted from the original signature to create a new set of roughness residuals, which are then given in the bottom panel. Note that these two profiles do not match, yet the ccf is 0.7724. The roughness correlation (-0.0324) correctly indicates the lack of matching. The roughness correlation acts as a check against false positives which can arise when there are significant deformations in the overall structure, as in the case with both these profiles.

```{r roughcorgood, echo=FALSE, fig.cap='Alignment of profile 40977 with 47600. The top panel shows the smoothed signatures. The middle panel overlays a LOESS fit to the average of the two signatures. Finally, to derive the roughness correlation, this LOESS is subtracted from the original signature to create a new set of roughness residuals, which are then given in the bottom panel. Note that these two profiles do not match, yet the ccf is 0.7724. The roughness correlation (-0.0324) correctly indicates the lack of matching.'}
bullets_smoothed <- my_signatures %>% filter(run_id == 3) %>% collect(n = Inf)

br1 <- filter(bullets_smoothed, profile_id == 40977) %>%
    dplyr::select(-run_id) %>%
    rename(bullet = profile_id) %>%
    filter(!is.na(l30))
br2 <- filter(bullets_smoothed, profile_id == 47600) %>%
    dplyr::select(-run_id) %>%
    rename(bullet = profile_id) %>%
    filter(!is.na(l30))

res <- bulletGetMaxCMS(br1, br2, column = "l30", span = 5)

prof1_zeroed <- br1 %>% 
    mutate(y = y - min(y),
           profile_id = factor(bullet))

prof2_zeroed <- br2 %>%
    mutate(y = y - min(y)) %>%
    mutate(y = y + res$lag,
           profile_id = factor(bullet))

final_profs <- rbind(prof1_zeroed, prof2_zeroed)

doublesmoothed <- final_profs %>%
    group_by(y) %>%
    mutate(avgl30 = mean(l30, na.rm = TRUE)) %>%
    ungroup() %>%
    mutate(smoothavgl30 = smoothloess(x = y, y = avgl30, span = 0.3),
           l50 = l30 - smoothavgl30)

ys <- intersect(prof1_zeroed$y, prof2_zeroed$y)
    
final_doublesmoothed <- doublesmoothed %>%
    filter(y %in% ys)

p1 <- ggplot(data = final_profs, aes(x = y, y = l30, colour = profile_id)) +
    geom_line() +
    theme_bw()

p2 <- ggplot(data = final_doublesmoothed, aes(x = y, y = l30, colour = profile_id)) +
    geom_line() +
    geom_smooth(inherit.aes = FALSE, aes(x = y, y = avgl30), colour = "purple") +
    theme_bw()

p3 <- ggplot(data = final_doublesmoothed, aes(x = y, y = l50, colour = profile_id)) +
    geom_line() +
    theme_bw()

grid.arrange(p1, p2, p3, nrow = 3)
```

In a typical comparison between two profiles, such as in Figure \ref{fig:roughcorfine}, the roughness correlation does not meaningfully impact the matching probability given the presence of the ccf in the model. In this figure, we see the alignment of profile 8752 with profile 136676. In this case, the waviness or the deformation pattern in the signatures is more minor, and hence the resulting roughness signature resembles the original signature more closely. These profiles match, and both ccf (0.6891) and rough_cor (0.7980) provide values indicative of matching.

```{r roughcorfine, echo=FALSE, fig.cap='Alignment of profile 8752 with profile 136676. In this case, the waviness or the deformation pattern in the signatures is more minor, and hence the resulting roughness signature resembles the original signature more closely. These profiles match, and both ccf (0.6891) and rough_cor (0.7980) provide values indicative of matching.'}

## DONE TODO: Sketch out process of rough cor (show loess, etc.)
## DONE Flip the two examples - say "roughness correlation doesnt affect matching prob" instead of "may not be needed" - but helps to identify mismatches
## DONE Change to percentages for Table 4.10
## Degraded: full bullet land from a lab, against a land split in half - lag max should be complete length of the other land. Either create hamby halves data and store in db, or run parameter to split in half (two parameters, a left and a right pixel) - ACTUALLY compare parameter, use signature. Make boxplot of left and right land effect. Plot of match probability of all known matches as a function of degraded percentage.
## Talk about matching full bullets (diagnonal)

br1 <- filter(bullets_smoothed, profile_id == 8752) %>%
    dplyr::select(-run_id) %>%
    rename(bullet = profile_id) %>%
    filter(!is.na(l30))
br2 <- filter(bullets_smoothed, profile_id == 136676) %>%
    dplyr::select(-run_id) %>%
    rename(bullet = profile_id) %>%
    filter(!is.na(l30))

res <- bulletGetMaxCMS(br1, br2, column = "l30", span = 5)

prof1_zeroed <- br1 %>% 
    mutate(y = y - min(y),
           profile_id = factor(bullet))

prof2_zeroed <- br2 %>%
    mutate(y = y - min(y)) %>%
    mutate(y = y + res$lag,
           profile_id = factor(bullet))

final_profs <- rbind(prof1_zeroed, prof2_zeroed)

doublesmoothed <- final_profs %>%
    group_by(y) %>%
    mutate(avgl30 = mean(l30, na.rm = TRUE)) %>%
    ungroup() %>%
    mutate(smoothavgl30 = smoothloess(x = y, y = avgl30, span = 0.3),
           l50 = l30 - smoothavgl30)

ys <- intersect(prof1_zeroed$y, prof2_zeroed$y)
    
final_doublesmoothed <- doublesmoothed %>%
    filter(y %in% ys)

p1 <- ggplot(data = final_profs, aes(x = y, y = l30, colour = profile_id)) +
    geom_line() +
    theme_bw()

p2 <- ggplot(data = final_doublesmoothed, aes(x = y, y = l30, colour = profile_id)) +
    geom_line() +
    geom_smooth(inherit.aes = FALSE, aes(x = y, y = avgl30), colour = "purple") +
    theme_bw()

p3 <- ggplot(data = final_doublesmoothed, aes(x = y, y = l50, colour = profile_id)) +
    geom_line() +
    theme_bw()

grid.arrange(p1, p2, p3, nrow = 3)
```

## Model Training

Using these features the randomForest [@randomForest] package, we can train a model which attempts to predict whether two lands match given the values of these features. We first join information on the study the data originated from, along with information on whether they are matches. The three studies currently contained in the database are Hamby (Set 252), Hamby (Set 44), and Cary. For purposes of the remainder of this analysis, we will exclude the Cary bullets from consideration. Because this was a study specifically designed to assess the persistence of striation markings over a series of fires from the same barrel, every Cary bullet is a known match to every other Cary bullet, although early firings do not produce the same markings that later firings do. Hence, we will consider Hamby (Set 252) and Hamby (Set 44) only.

```{r, echo=FALSE, cache=FALSE}
con <- dbConnect(MySQL(), user = user, password = password,
                 dbname = dbname, host = host)

all_bullets_metadata <- dbReadTable(con, "metadata")
my_matches <- dbReadTable(con, "matches")
profiles <- dbReadTable(con, "profiles")
ccf <- dbReadTable(con, "ccf") %>% filter(compare_id == 4)

CCFs_withlands <- ccf %>%
    left_join(dplyr::select(profiles, profile_id, land_id), by = c("profile1_id" = "profile_id")) %>%
    left_join(dplyr::select(profiles, profile_id, land_id), by = c("profile2_id" = "profile_id")) %>%
    left_join(my_matches, by = c("land_id.x" = "land1_id", "land_id.y" = "land2_id")) %>%
    left_join(dplyr::select(all_bullets_metadata, land_id, study, barrel, bullet, land), by = c("land_id.x" = "land_id")) %>%
    left_join(dplyr::select(all_bullets_metadata, land_id, study, barrel, bullet, land), by = c("land_id.y" = "land_id")) %>%
    filter(study.x != "Cary", study.y != "Cary") %>%
    arrange(study.x, study.y) %>%
    mutate(match = as.logical(replace(match, is.na(match), 0)))
```

We can now train the forest using the previously defined features. We split the data into an 80% training, 20% testing framework to assess its out of sample performance, using the `caret` package [@caretpkg]. Table \ref{tab:avgforest} provides the results as a confusion matrix on the test set, averaged over ten independent random forests trained on ten random data subsets. It can be seen that false positives are exceedingly rare, but false negatives occur more frequently (approximately 23 false negative land to land comparisons on the test set, compared with an average of less than one false positive).

```{r, echo=FALSE, results='asis'}
includes <- setdiff(names(CCFs_withlands), c("compare_id", "profile1_id", "profile2_id",
                                         "study.x", "study.y", "barrel.x", "barrel.y",
                                         "bullet.x", "bullet.y", "land.x", "land.y",
                                         "land_id.x", "land_id.y"))

set.seed(20170222)
trainIndex <- createDataPartition(1:nrow(CCFs_withlands), p = 0.8, list = TRUE, times = 10)
match_result <- trainIndex %>% purrr::map_df(function(index) {
    CCFs_train <- CCFs_withlands[index,]
    CCFs_test = setdiff(CCFs_withlands, CCFs_train)
    
    rtrees <- randomForest(factor(match) ~ ., data = CCFs_train[,includes], ntree = 300)
    
    CCFs_test$forest <- predict(rtrees, newdata = CCFs_test, type = "prob")[,2]
    imp <- data.frame(importance(rtrees))
    confmat <- as.data.frame(xtabs(~(forest > 0.5) + match + study.x + study.y, data = CCFs_test))
    names(confmat) <- c("Prediction", "Actual", "study.x", "study.y", "Count")
    
    mydf <- confmat %>%
        mutate(Study = paste(study.x, study.y, sep = "_"),
               Result = rep(c("True Negative", "False Positive", "False Negative", "True Positive"), times = length(unique(Study)))) %>%
        mutate(Study = replace(Study, which(Study == "Hamby44_Hamby252"), "Hamby252_Hamby44")) %>%
        dplyr::select(Study, Result, Count) %>%
        group_by(Study, Result) %>%
        summarise(Count = sum(Count)) %>%
        as.data.frame
    
    return(mydf)
}) 
match_result <- cbind(id = rep(1:10, each = nrow(match_result) / 10), match_result)
match_result_wide <- match_result %>%
    spread(key = Result, value = Count)

result <- match_result %>%
    group_by(Result) %>%
    summarise(Count = mean(Count))

print(xtable(result, digits = c(0, 0, 1), label = "tab:avgforest", caption = "The average confusion matrix for the 10 random forests. It can be seen that false positives are exceedingly rare, but false negatives occur more frequently."), comment = FALSE, include.rownames = FALSE, table.placement = "H")
```

These results suggest that our algorithm is a bit too conservative in predicting a match when in fact the bullets were fired from the same gun barrel. We can break down the confusion matrix depending on the study that each of the two lands originated from. Table \ref{tab:avgforeststudy} provides the average confusion matrix for the 10 random forests, broken down by study. It can be seen that Hamby252 to Hamby252 comparisons exhibit the fewest errors, while Hamby252 to Hamby44 comparisons exhibit the most on average. This intuitively makes some sense given the presence of potential scanner operator effects, which we will address further in this section.

```{r, echo=FALSE, results='asis'}
result <- match_result %>%
    group_by(Study, Result) %>%
    summarise(Count = mean(Count)) %>%
    spread(key = Result, value = Count)

result_wide_row <- result
result_wide_row[,-1] <- t(apply(result_wide_row[,-1], 1, function(x) paste0(round(100 * x / sum(x), digits = 2), "%")))

print(xtable(result_wide_row, label = "tab:avgforeststudy", caption = "The average confusion matrix for the 10 random forests, broken down by study. It can be seen that Hamby252 to Hamby252 comparisons exhibit the fewest errors, while Hamby252 to Hamby44 comparisons exhibit the most on average."), comment = FALSE, include.rownames = FALSE, table.placement = "H")
```

## Operator Effects

We can attempt to quantify the effect of the study on the matching probability by fitting a new random forest which attempts to predict the study based on the derived features. Ideally, if the assumption of independence between lands holds across different operators, this forest should have poor performance - The set of derived features should be relatively consistent among known matches and known non-matches regardless of the study since the Hamby data in both sets originated from the same gun barrels.

```{r, echo=FALSE}
includes_study <- setdiff(names(CCFs_withlands), c("compare_id", "profile1_id", "profile2_id",
                                         "barrel.x", "barrel.y", "match",
                                         "bullet.x", "bullet.y", "land.x", "land.y",
                                         "land_id.x", "land_id.y", "study.x", "study.y"))

result_study <- trainIndex %>% purrr::map_df(function(index) {
    CCFs_train <- CCFs_withlands[index,]
    CCFs_test = setdiff(CCFs_withlands, CCFs_train)
    
    CCFs_train$Study <- paste(CCFs_train$study.x, CCFs_train$study.y, sep = "_")
    CCFs_test$Study <- paste(CCFs_test$study.x, CCFs_test$study.y, sep = "_")
    CCFs_train$Study <- factor(replace(CCFs_train$Study, which(CCFs_train$Study == "Hamby44_Hamby252"), "Hamby252_Hamby44"))
    CCFs_test$Study <- factor(replace(CCFs_test$Study, which(CCFs_test$Study == "Hamby44_Hamby252"), "Hamby252_Hamby44"))
    
    includes_study <- setdiff(names(CCFs_train), c("compare_id", "profile1_id", "profile2_id", "barrel.x", "barrel.y", "match", "bullet.x", "bullet.y", "land.x", "land.y", "land_id.x", "land_id.y", "study.x", "study.y"))

    rtrees_study <- randomForest(Study ~ ., data = CCFs_train[,includes_study], ntree = 300)
    
    CCFs_test$study_forest <- predict(rtrees_study, newdata = CCFs_test)
    confmat <- as.data.frame(xtabs(~study_forest + Study, data = CCFs_test))
    names(confmat) <- c("Prediction", "Actual", "Count")
    
    return(confmat)
})
```

Table \ref{tab:studypred} provides the confusion matrix, with column proportions, for the random forest with study as the response. It can be seen that while overall the random forest performs poorly, as hoped, comparisons between Hamby252 bullets are more distinguishable from other comparisons.

```{r, echo=FALSE, results='asis'}
study_result <- cbind(id = rep(1:10, each = nrow(result_study) / 10), result_study)
study_result_wide <- study_result %>%
    spread(key = Actual, value = Count) %>%
    group_by(Prediction) %>%
    summarise_each(funs(mean)) %>%
    select(-id) %>%
    as.data.frame
study_result_wide_col <- study_result_wide
study_result_wide_col[,-1] <- apply(study_result_wide_col[,-1], 2, function(x) paste0(round(100 * x / sum(x), digits = 2), "%"))

print(xtable(study_result_wide_col, digits = c(0, 0, 3, 3, 3), label = "tab:studypred", caption = "Confusion Matrix (Column Proportions) for the random forest with study as the response. It can be seen that while overall the random forest performs poorly, as hoped, comparisons between Hamby252 bullets is more distinguishable from other comparisons."), comment = FALSE, include.rownames = FALSE, table.placement = "H")
```

Figure \ref{fig:ccfstudy} give the distributions of the features defined above, faceted by whether the lands are known to be fired from the same gun barrel, across different study to study comparisons. The distributions among the known non-matches seem relatively consistent across study based on visual inspection. On the other hand, among known matches, Hamby252 to Hamby252 comparisons exhibit more pronounced features, including a higher average ccf, higher number of matches, and higher value of sum_peaks.

```{r ccfstudy, echo=FALSE, message=FALSE, fig.cap="Distribution of the features, facetted by match, for different study to study comparisons of lands.", fig.height=13, fig.width=10}
CCFs_features <- CCFs_withlands %>%
    mutate(Study = factor(paste(study.x, study.y, sep = "_"))) %>%
    mutate(Study = replace(Study, which(Study == "Hamby44_Hamby252"), "Hamby252_Hamby44")) %>%
    select(-matches("_id|study.x|study.y|barrel|bullet|land|signature_length|non_cms|sd_D|lag")) %>%
    select(Study, match, everything()) %>%
    mutate(match = factor(match, labels = c("Known Non-Match", "Known Match"))) %>%
    gather(key = feature, value = value, 3:ncol(.))

## DONE TODO: Name FALSE/TRUE Known Matches / Known Non-Matches
## DONE INCLUDE number of points for each comparison
## DONE Exclude Cary. Show 252-252 looks a bit strange - the features are particularly good.
## DONE Run forest without cary
## DONE Talk about operator or scan demographics needing to be included. Need rigorous procedures in place
## DONE Pull out "D" statistic for KS tests, looks at vertical difference. Put with p-value.

ggplot(CCFs_features, aes(x = Study, y = value)) +
    geom_boxplot() +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 90)) +
    facet_grid(feature~match, scales = "free") +
    ggtitle("Distributions of Features by Study and Match") +
    xlab("Study") +
    ylab("Value")
```

We can assess the differences in the distributions formally with a Kolmogrov-Smirnov test. Table \ref{tab:kstests} gives the results of pairwise tests, for each feature, between different set comparisons, and between known matches compared with known non-matches. Although the tests are significant, looking at the raw values of the D statistic suggest that the largest effect sizes do in fact occur in comparisons with two Hamby252 lands, as the visual inspection of the boxplots also suggested.

```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, results='asis'}
all_combinations <- combn(unique(c(as.character(CCFs_features$Study), as.character(CCFs_features$Study))), 2, simplify = FALSE)

myresult <- all_combinations %>% map_df(function(x) {
    final_result <- try({
        set1 <- filter(CCFs_features, Study == x[1])
        set2 <- filter(CCFs_features, Study == x[2])
        
        result <- set1 %>%
            rbind(set2) %>%
            group_by(feature) %>%
            do(matchtest = ks.test(x = filter(., Study == x[1])$value[filter(., Study == x[1])$match == "Known Match"], y = filter(., Study == x[2])$value[filter(., Study == x[2])$match == "Known Match"])$p.value,
               matchd = ks.test(x = filter(., Study == x[1])$value[filter(., Study == x[1])$match == "Known Match"], y = filter(., Study == x[2])$value[filter(., Study == x[2])$match == "Known Match"])$statistic,
               nonmatchtest = ks.test(x = filter(., Study == x[1])$value[filter(., Study == x[1])$match == "Known Non-Match"], y = filter(., Study == x[2])$value[filter(., Study == x[2])$match == "Known Non-Match"])$p.value,
               nonmatchd = ks.test(x = filter(., Study == x[1])$value[filter(., Study == x[1])$match == "Known Non-Match"], y = filter(., Study == x[2])$value[filter(., Study == x[2])$match == "Known Non-Match"])$statistic,
               set1_matchcount = length(filter(., Study == x[1])$value[filter(., Study == x[1])$match == "Known Match"]),
               set1_nonmatchcount = length(filter(., Study == x[1])$value[filter(., Study == x[1])$match == "Known Non-Match"]),
               set2_matchcount = length(filter(., Study == x[2])$value[filter(., Study == x[1])$match == "Known Match"]),
               set2_nonmatchcount = length(filter(., Study == x[2])$value[filter(., Study == x[1])$match == "Known Non-Match"])
               
            )
    })
    
    if (inherits(final_result, "try-error")) return(NULL)
    
    return(final_result %>% mutate(set1 = x[1], set2 = x[2]) %>% select(set1, set2, everything()) %>% as.data.frame)
})

final_result <- myresult %>%
    mutate(set1 = gsub("Hamby", "H", set1),
           set2 = gsub("Hamby", "H", set2)) %>%
    as.data.frame

print(xtable(final_result[,1:7], digits = c(0, 0, 0, 0, 3, 3, 3, 3), label = "tab:kstests", caption = "Results for the Kolmogrov-Smirnov distributional test."), comment = FALSE, include.rownames = FALSE)
```

These results strongly suggest the need for controlling for more effects when performing the analysis. Specifically, microscope operator effects resulting in variations in scan quality and scan parameters seem to play a role in the utlimate performance of the algorithm. Land to land comparisons from Hamby252 consistently result in more pronounced expression of features among known matches, and therefore result in a better ultimate accuracy in the random forest. Rigorous procedures to ensure scan quality and consistency across operators should be put in place to minimize the effect of the study and ensure the assumption of land to land independence is satisfied.

Another way to demostrate the study/operator effect is by observing the distribution of our algorithm's ideal cross section by study. Figure \ref{fig:crosscompare} gives the distributions of the ideal cross sections by study. It can be seen that the Hamby44 ideal cross sections are much more likely to be close to the base of the bullet compared to Hamby252.

```{r crosscompare, echo=FALSE, fig.cap='Distributions of the ideal cross sections by study. It can be seen that the Hamby44 ideal cross sections are much more likely to be close to the base of the bullet compared to Hamby252.'}
result <- dbReadTable(con, "metadata_derived") %>%
    left_join(dplyr::select(all_bullets_metadata, land_id, study)) %>%
    filter(run_id == max(run_id)) %>%
    dplyr::select(land_id, ideal_crosscut, study) %>%
    filter(!is.na(ideal_crosscut), study != "Cary")

ggplot(result, aes(x = study, y = ideal_crosscut)) +
    geom_boxplot() +
    theme_bw() +
    ylim(c(0, 400)) +
    ggtitle("Distribution of Ideal Cross Section by Study")
```

Indeed, another Kolmogorov-Smirnov test also confirms a significant difference in the distributions of these values. The result of this test is provided in Table \ref{tab:mykstest}. Because the difference is significant, it strongly suggests that the operator effect in the bullet scanning procedure must be taken into account in order to assume pairwise independence.

```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
mytest <- ks.test(x = result$ideal_crosscut[result$study == "Hamby252"], y = result$ideal_crosscut[result$study == "Hamby44"])

print(xtable(tidy(mytest), digits = c(0, 4, 4, 0, 0), label = "tab:mykstest", caption = "Results for the Kolmogrov-Smirnov distributional test between values of the ideal cross section for Hamby252 compared with Hamby44."), comment = FALSE, include.rownames = FALSE)
```

## Degraded Bullets

```{r, echo=FALSE, eval=FALSE}
load("data/rtrees.RData")

ccf <- dbReadTable(con, "ccf") %>% filter(compare_id == 5)
CCFs_withlands_left <- ccf %>%
    left_join(dplyr::select(profiles, profile_id, land_id), by = c("profile1_id" = "profile_id")) %>%
    left_join(dplyr::select(profiles, profile_id, land_id), by = c("profile2_id" = "profile_id")) %>%
    left_join(my_matches, by = c("land_id.x" = "land1_id", "land_id.y" = "land2_id")) %>%
    left_join(dplyr::select(all_bullets_metadata, land_id, study, barrel, bullet, land), by = c("land_id.x" = "land_id")) %>%
    left_join(dplyr::select(all_bullets_metadata, land_id, study, barrel, bullet, land), by = c("land_id.y" = "land_id")) %>%
    filter(study.x != "Cary", study.y != "Cary") %>%
    arrange(study.x, study.y) %>%
    mutate(match = as.logical(replace(match, is.na(match), 0)))

CCFs_withlands_left$forest <- predict(rtrees, newdata = CCFs_withlands_left, type = "prob")[,2]
xtabs(~(forest > 0.5) + match, data = CCFs_withlands_left)
```

# Conclusion

In this paper, we have introduced and described a formal database housing raw bullet data, and the results of each processing stage of our bullet matching algorithm. Because this database is openly accessible, and all parameters are tracked, this allows for researchers to more easily use the results in order to iterate on components of the algorithm in hopes of improving the matching performance. To this end, we have also performed a case study feature analysis in which we used the derive pairwise features to train a model, strongly suggesting the presence of operator effects in the scanning process that must be accounted for.

The way in which this should be accounted for is less clear, however. In the ideal case, bullets fired from a particular gun barrel should yield surface scans that are of identical quality and properties, regardless of the operator performing the scan. To achieve this, rigorous standards may need to be put in place with regards to the alignment of the bullet under the objective, and the procedure used to scan the bullet surface. Such procedures will require further investigation in order to lay out. For instance, due to the stark difference between the ideal cross section across two studies, procedures may need to dictate the margin from the edge of the objective at which the bullet can be placed.

