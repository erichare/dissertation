---
title: "Proposal: Enabling Scientists to Understand their Data using Web-Based Statistical Tools"
author: "Eric Hare"
date: "June 10, 2016"
output: pdf_document
bibliography: references.bib
---

## Introduction

The computing revolution has opened up statistical methods and tools to a broad range of fields. With the growing popularity of R in particular, the wide range of choices of open source statistical routines in the form of packages has significantly expanded statistical computing capabilities. Still, there remains a fundamental obstacle to the use of R. Effective use of R requires a commitment to learning and understanding programming, which some individuals, companies, and researchers may not have the time or desire to do. Furthermore, although the open-source nature of R is one of its biggest assets, it also means that there is a more rapid development cycle than would often be found in more corporate software solutions. This means that R developers must continue to maintain their code while learning new programming concepts.

A number of tools have been developed in an attempt to address this issue. The commerical software on which R is derived, S-PLUS, includes a rudimentary graphical user interface (GUI) supporting data editing, graphing, and basic statistics. Over time, GUIs were developed for R as well. One of the first was R Commander, which provides a wrap-around user interface for R. With drop-down menus allowing point-and-click selection of a number of common data analysis and statistical functions, analysis could be performed without a knowledge of programming. More recently, the program Deducer also abstracts the programming into graphical menus and buttons. It expands on R Commander by providing an effective data viewer, help system, and easy to read tables displaying the results.

GUIs have some natural limitations that often make them a less appealing option for researchers. The results of an analysis from a GUI are not typically reproducible. Whereas an R script can be created, shared, and executed elsewhere, the actions taken in a GUI are not transcribed and portable. GUIs also tend to slow down the development and iteration process once the user has become more comfortable with the programming concepts. For instance, scripts allow copying and pasting of code blocks that need only minor modifications. In a GUI, the options representing a code block would need to be individually chosen through drop-down menus.

Recognizing some of these limitations, other approaches have been taken to easing the transition to working with R. RStudio provides a GUI around R with expanded functionality, but maintains focus on the scripting and coding aspect. In this sense, RStudio more readily resembles an IDE (Integrated Development Environment), which aid the programmer rather than attempting to abstract the programming away. While this allows reproducibility and may still help a less experienced programmer begin to get started in a programming language, it still depends on a continuing effort to learn programming.

Essentially, we can partition researchers into three broad sets:

1. Those who have no interest in using statistics to aid their research
2. Those who have interest in using statistics to aid their research, and have a knowledge of or interest in gaining a knowledge of programming
3. Those who have interest in using statistics to aid their research, but have no interest in programming, or significantly struggle in programming

We can hope to change the minds of the people in set 1, moving them into sets 2 or 3. Those in set 2 have most to gain from the use of R and/or RStudio. On the other hand, those in set 3 have the most to gain from effective GUIs that do not require programming knowledge. The Shiny package for R provides a framework for researchers who fall in set 2 to provide a service to those in set 3. Shiny is a web development framework which can help turn the results of an R analysis into an interactive web application. Results can be generated by browsing to the website at which the Shiny application is deployed, and using GUI elements (dropdowns, text boxes, tabs) similar to R Commander or Deducer in order to generate results. But a Shiny application is standard R code, and hence maintains the reproducibility and maintainability benefits of standard R scripts.

Because Shiny offers a solution which maintains the benefits of both GUIs and standard programming, I believe it can form the basis for a new set of tools and concepts that greatly expand the reach of statistics. Those who are comfortable with programming can now provide functionality to those who aren't. This functionality can enable researchers to see, understand, and work with their data in ways that they were simply unable to.

I have focused on three broad areas that can benefit from graphical rather than purely programmatic tools:

1. Forensic Science
2. Statistics Education
3. Visual Inference

Each of these areas, I believe, can benefit significantly from functionality present in R and associated packages. But for the forseeable future, each field will also include a significant number of students, researchers, and scientists that have little-to-no knowledge of R, and will therefore be dissuaded from attempting its use. Working at the interface of Statistics and Computer Science, I will explain the current state of the art in each of these fields, and how a reproducible R and web-based solution can help to address the current shortcomings.

## Forensic Science

The judicial system would seem to be an especially good candidate for the integration of a statistical approach. In the United States, suspects are considered innocent until proven guilty "beyond a reasonable doubt". This in many ways parallels traditional hypothesis testing approaches, in which a pre-defined cut-off (significance level) is used to determine the threshold at which the null hypothesis is rejected (which presumably should occur once the evidence leads us beyond a reasonable doubt). 

But such probabilistic thinking doesn't always occur. In particular, bullet matching, or the process of determining whether two bullets were fired from the same gun barrel, has been the subject of intense scrutiny in the past 15 years. In 2005, in *United States vs. Green*, the court ruled that the forensic expert in question could not confirm that the bullet casings came from a specific weapon with certainty, but could merely "describe" other casings which are similar. Further court cases in the late 2000s expressed caution about the use of firearms identification evidence [@giannelli:2011]. This scrutiny culminated in the 2009 National Academy of Sciences report questioning the scientific validity of many forensic methods including firearm examination. The report states that "[m]uch forensic evidence -- including, for example, bite marks and firearm and toolmark identification is introduced in criminal trials without any meaningful scientific validation, determination of error rates, or reliability testing to explain the limits of the discipline" [@NAS:2009].

Rifling, manufacturing defects, and impurities in a barrel create striation marks on the bullet during the firing process. These marks are assumed to be unique to the barrel, as described in a 1992 AFTE article [@afte:1992]. Current standard practice for bullet matching relies in part on the assessment of the so-called maximum number of consecutively matching striae (CMS), first defined by @biasotti:1959. One of the primary issues with this procedure is that a human inspection to determine CMS is subjective [@miller:1998]. Human inspection also requires on-site analysis of the bullets, which can be costly and time-consuming, and introduces the potential for differing opinions across different forensic examiners.

A modern development in this realm is the adoption of an open format for storing 3D topographical images of bullets in a format called x3p (XML 3-D Surface Profile). The x3p format conforms to the ISO5436-2 standard\footnote{\url{http://sourceforge.net/p/open-gps/mwiki/X3p/}}, implemented to provide a simple and standard conforming way to exchange 2D and 3D profile data. It was adopted by the OpenFMC (Open Forensic Metrology Consortium\footnote{\url{http://www.openfmc.org/}}), a group of academic, industry, and government firearm forensics researchers whose aim is to establish best practices for researchers using metrology in forensic science. Furthermore, NIST (the National Institute for Standards and Technology) is developing a database to allow searching and downloading of these x3p files\footnote{\url{https://tsapps.nist.gov/NRBTD/}}.

## Statistics Education

## Visual Inference

## Conclusion

## References
